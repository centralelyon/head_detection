{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLSqL3eGUfeO"
      },
      "source": [
        "### Testing notebook to execute a trained Faster-RCNN to detect swimmers' head on images or videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUxt2gzYUedX"
      },
      "source": [
        "#import pycotools\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('gdrive/My Drive/Stage_LIRIS/pytorch_object_detection') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cko7m6ZkJSuS"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow #cv2.imshow doesnt work with Google Colab\n",
        "\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mW96ANfVYYs"
      },
      "source": [
        "to_load_path = './model.pt' #Path towards the dictionnary which contains the weights of a trained Faster-RCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yeIIQIRU2ua"
      },
      "source": [
        "The first cell allows you to test the model on any image.\n",
        "\n",
        "The secund cell allows you to test the model on a (zoomed) video. The path to the video must be specified. Without GPU acceleration, the calculations are long (about 4 seconds per frame of video of size 256x256). The path to the video must be specified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fopXfskPUuDs"
      },
      "source": [
        "def analyse_image(image_path, thresh, model_path, colab=False) :\n",
        "  \"\"\"\n",
        "  Parameters :\n",
        "  image_path : path towards the image to analyse\n",
        "  thresh : only detections with score above threshold are kept\n",
        "  model_path : path towards the dictionnary which contains the weights of a trained Faster-RCNN\n",
        "  colab : True if executing the notebook online (google Colab), False if executed locally.\n",
        "\n",
        "  The function shows the image with rectangles drawn on the detections\n",
        "  \"\"\"\n",
        "  \n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
        "\n",
        "  loaded_model = get_model(num_classes = 2)\n",
        "  loaded_model.load_state_dict(torch.load(model_path+'/'+nom_load_model, map_location=device))\n",
        "  loaded_model.to(device)\n",
        "\n",
        "  img_cv = cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
        "  img= T.ToTensor()(img)[0].to(device)\n",
        " \n",
        "  #put the model in evaluation mode\n",
        "  loaded_model.eval()\n",
        "  with torch.no_grad():\n",
        "      prediction = loaded_model([img])\n",
        "  \n",
        "  for element in range(len(prediction[0][\"boxes\"])):\n",
        "      boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
        "      score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
        "                      decimals= 4)\n",
        "      \n",
        "      if score >= thresh:\n",
        "        top_left = (int(boxes[0]), int(boxes[1]))\n",
        "        bottom_right = (int(boxes[2]), int(boxes[3]))\n",
        "        img_cv = cv2.rectangle(img_cv, top_left, bottom_right, (0,255,0),2) #draw a rectangle\n",
        "        img_cv = cv2.putText(img_cv, str(score), (top_left[0], bottom_right[1]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,255,0), 1) #draw score\n",
        "\n",
        "  if colab : #cv2.imshow doesnt work with Google Colab\n",
        "    cv2_imshow(img_cv)\n",
        "  else : \n",
        "    cv2.imshow(img_cv)\n",
        "  \n",
        "analyser_image('./swimmer/images/above140.png',0.8, to_load_path )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Oi1UpPHUvp0"
      },
      "source": [
        "# test sur une video\n",
        "\n",
        "def analyse_video(video_path, out_path, thresh, model_path) :\n",
        "  \"\"\"\n",
        "  Parameters :\n",
        "  video_path : path towards the video to analyse\n",
        "  out_path : path towards the video with rectangles on detections\n",
        "  thresh : only detections with score above threshold are kept\n",
        "  model_path : path towards the dictionnary which contains the weights of a trained Faster-RCNN\n",
        "\n",
        "  The function writes a video at the requested location with each frame showing the\n",
        "  bounding boxes detected by the Faster-RCNN with the requested threshold\n",
        "  \n",
        "  It returns a \"box_head\" list such that for each frame i, box_head[i] is a \n",
        "  list of lists of the form [frame, top_left, bottom_right] for each bounding box \n",
        "  on frame i  where frame is the number of the frame, top_left and botom_right are \n",
        "  the top left and bottom right point of the bouding box of the detection\n",
        "  \"\"\"\n",
        "\n",
        "  # use GPU if CUDA is available otherwise use CPU\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
        "\n",
        "  loaded_model = get_model(num_classes = 2)\n",
        "  loaded_model.load_state_dict(torch.load(model_path+\"/\"+nom_load_model, map_location=device))\n",
        "  loaded_model.to(device)\n",
        "\n",
        "  box_head = []\n",
        "\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float \n",
        "  height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) # float\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "  out = cv2.VideoWriter(out_path, fourcc, fps, (int(width),  int(height)))\n",
        "  length = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "  #put the model in evaluation mode\n",
        "  loaded_model.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    while(True):\n",
        "        # Capture frame-by-frame\n",
        "        ret, frame = cap.read()\n",
        "        num_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "        print(str(num_frame)+' on '+str(length))\n",
        "\n",
        "        if ret :\n",
        "          img = frame\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #RGB \n",
        "          im_tensor = T.ToTensor()(img)[0].to(device) #tensor \n",
        "\n",
        "        \n",
        "          detection = loaded_model([im_tensor])\n",
        "\n",
        "          \n",
        "          N = len(detection[0]['boxes']) #Number of detections\n",
        "          boxes = []\n",
        "          for n in range(N) : \n",
        "            xmin, ymin,xmax, ymax = detection[0]['boxes'][n]\n",
        "            score = detection[0]['scores'][n].item()\n",
        "\n",
        "            if score>= thresh : \n",
        "              top_left = (int(xmin.item()), int(ymin.item()))\n",
        "              bottom_right = (int(xmax.item()), int(ymax.item()))\n",
        "              frame = cv2.rectangle(frame, top_left,bottom_right , (0,255,0), 2)\n",
        "              boxes.append([num_frame, top_left, bottom_right])\n",
        "              \n",
        "\n",
        "          box_head.append(boxes)\n",
        "\n",
        "              \n",
        "          out.write(frame)\n",
        "\n",
        "        else :\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    return box_head\n",
        "\n",
        "box_head = analyse_video('./swimmer/zoom_4K.mp4', './swimmer/resultats/zoom_4K_out.mp4', 0.8, to_load_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
